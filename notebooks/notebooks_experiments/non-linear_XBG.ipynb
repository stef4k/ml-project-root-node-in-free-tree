{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a624ef1-ee6a-4ec8-a7ed-296b49cd228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.model_selection  import GroupShuffleSplit\n",
    "from itertools                import product\n",
    "from tqdm                     import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e29677",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_FEATS_PATH   = '../../data/normalized_expanded_train.csv'\n",
    "TRAIN_META_PATH    = '../../data/train.csv'\n",
    "TEST_FEATS_PATH    = '../../data/normalized_expanded_test.csv'\n",
    "TEST_META_PATH     = '../../data/test.csv'\n",
    "LABELED_TEST_PATH  = '../../data/labeled_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d36e76-483e-4e7b-8cfb-81cd05fe609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'n','degree','closeness','harmonic','betweeness','load','pagerank',\n",
    "    'eigenvector','katz','information','current_flow_betweeness',\n",
    "    'percolation','second_order','laplacian'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34560c7-0e71-4bc8-ad95-fd69016d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "  'max_depth':        [4,6,8],\n",
    "  'eta':               [0.01,0.05,0.1],\n",
    "  'subsample':        [0.7,1.0],\n",
    "  'colsample_bytree': [0.7,1.0],\n",
    "  'gamma':            [0,1],\n",
    "  # new ones:\n",
    "  'min_child_weight': [1,5,10],\n",
    "  'reg_alpha':        [0,0.01,0.1],\n",
    "  'reg_lambda':       [1,10,100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93c55eb-4245-409e-ab89-f259ff3389a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom root‐accuracy scoring (1 root per sentence)\n",
    "def root_score(sent_ids, y_true, probs):\n",
    "    dfp = pd.DataFrame({'sent': sent_ids, 'y': y_true, 'p': probs})\n",
    "    picks = dfp.loc[dfp.groupby('sent')['p'].idxmax()]\n",
    "    return (picks.y == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791b5109-89df-44c7-8fdf-1badd4096e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data…\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data…\")\n",
    "exp  = pd.read_csv(TRAIN_FEATS_PATH)\n",
    "meta = pd.read_csv(TRAIN_META_PATH)\n",
    "meta['edgelist'] = meta['edgelist'].apply(ast.literal_eval)\n",
    "df   = exp.merge(\n",
    "    meta[['language','sentence','edgelist','root']],\n",
    "    on=['language','sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6174aae8-30a8-4893-b12f-472c98999146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Tuning per-language XGB on GPU with early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▌                                                                                                                | 1/21 [10:53<3:37:43, 653.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic       → val-root-acc=0.570  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.4775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▏                                                                                                          | 2/21 [26:14<4:16:51, 811.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese      → val-root-acc=0.340  best_round=6  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0.1, 'lambda': 1, 'scale_pos_weight': 17.5475, 'seed': 42, 'verbosity': 0, 'ntree_limit': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▊                                                                                                     | 3/21 [44:00<4:38:15, 927.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech        → val-root-acc=0.610  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.0875, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████▍                                                                                               | 4/21 [59:22<4:22:06, 925.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English      → val-root-acc=0.680  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.715, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████▌                                                                                        | 5/21 [1:11:08<3:45:39, 846.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnish      → val-root-acc=0.570  best_round=7  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 12.5775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▏                                                                                  | 6/21 [1:26:21<3:37:14, 868.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French       → val-root-acc=0.480  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 21.4075, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████▋                                                                             | 7/21 [1:42:51<3:32:00, 908.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galician     → val-root-acc=0.550  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.0975, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████████████▏                                                                       | 8/21 [1:56:39<3:11:17, 882.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German       → val-root-acc=0.650  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.695, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████▋                                                                  | 9/21 [2:13:49<3:05:45, 928.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi        → val-root-acc=0.320  best_round=17  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.6575, 'seed': 42, 'verbosity': 0, 'ntree_limit': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████████▊                                                            | 10/21 [2:26:39<2:41:18, 879.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icelandic    → val-root-acc=0.540  best_round=0  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.73, 'seed': 42, 'verbosity': 0, 'ntree_limit': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████████████████████▏                                                      | 11/21 [2:41:31<2:27:15, 883.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indonesian   → val-root-acc=0.560  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 1, 'scale_pos_weight': 16.1, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████████████████▋                                                 | 12/21 [2:58:44<2:19:20, 928.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian      → val-root-acc=0.550  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.595, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████▌                                           | 13/21 [3:20:15<2:18:27, 1038.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese     → val-root-acc=0.150  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 1, 'scale_pos_weight': 24.7675, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████▋                                      | 14/21 [3:33:50<1:53:17, 971.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean       → val-root-acc=0.370  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 14.02, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████████████▏                                | 15/21 [3:40:30<1:19:54, 799.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish       → val-root-acc=0.650  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 14.8325, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████▌                           | 16/21 [3:55:06<1:08:30, 822.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese   → val-root-acc=0.510  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 19.825, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████▋                      | 17/21 [4:08:02<53:52, 808.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian      → val-root-acc=0.670  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.4125, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 18/21 [4:21:58<40:49, 816.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish      → val-root-acc=0.500  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.0925, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 19/21 [4:35:12<26:59, 809.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swedish      → val-root-acc=0.650  best_round=8  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 6, 'eta': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 16.1525, 'seed': 42, 'verbosity': 0, 'ntree_limit': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 20/21 [4:51:49<14:26, 866.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thai         → val-root-acc=0.620  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 6, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 21.0775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [5:02:11<00:00, 863.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turkish      → val-root-acc=0.480  best_round=22  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 8, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 13.8225, 'seed': 42, 'verbosity': 0, 'ntree_limit': 22}\n",
      "\n",
      "Tuning completed in 5:02:12.004304\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "t0 = time()\n",
    "print(\"→ Tuning per-language XGB on GPU with early stopping\\n\")\n",
    "\n",
    "for lang in tqdm(sorted(df.language.unique())):\n",
    "    sub = df[df.language == lang].reset_index(drop=True)\n",
    "\n",
    "    # 1) 80/20 sentence-wise split\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    tr_idx, val_idx = next(gss.split(sub, sub.root, groups=sub.sentence))\n",
    "    train, val = sub.iloc[tr_idx], sub.iloc[val_idx]\n",
    "\n",
    "    # 2) scale features\n",
    "    scaler = StandardScaler().fit(train[FEATURES])\n",
    "    X_tr = scaler.transform(train[FEATURES])\n",
    "    y_tr = (train.root == train.vertex).astype(int)\n",
    "    X_val = scaler.transform(val[FEATURES])\n",
    "    y_val = (val.root   == val.vertex  ).astype(int)\n",
    "\n",
    "    # 3) build DMatrix\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # class‐imbalance weight\n",
    "    pos = y_tr.sum();  neg = len(y_tr) - pos\n",
    "    spw = (neg/pos) if pos>0 else 1.0\n",
    "\n",
    "    best_sc, best_cfg, best_bst = -1, None, None\n",
    "\n",
    "    # 4) exhaustive grid‐search over all your hyperparams\n",
    "    for md, eta, subs, colsm, gm, mcw, alpha, lmbda in product(\n",
    "        param_grid['max_depth'],\n",
    "        param_grid['eta'],\n",
    "        param_grid['subsample'],\n",
    "        param_grid['colsample_bytree'],\n",
    "        param_grid['gamma'],\n",
    "        param_grid['min_child_weight'],\n",
    "        param_grid['reg_alpha'],\n",
    "        param_grid['reg_lambda'],\n",
    "    ):\n",
    "        cfg = {\n",
    "            'objective':         'binary:logistic',\n",
    "            'eval_metric':       'error',       # basic validation‐error\n",
    "            'tree_method':       'hist',\n",
    "            'device':            'cuda',\n",
    "            'max_depth':         md,\n",
    "            'eta':               eta,\n",
    "            'subsample':         subs,\n",
    "            'colsample_bytree':  colsm,\n",
    "            'gamma':             gm,\n",
    "            'min_child_weight':  mcw,\n",
    "            'alpha':             alpha,\n",
    "            'lambda':            lmbda,\n",
    "            'scale_pos_weight':  spw,\n",
    "            'seed':              42,\n",
    "            'verbosity':         0,\n",
    "        }\n",
    "\n",
    "        # 5) train up to 200 rounds, early-stop on validation‐error\n",
    "        bst = xgb.train(\n",
    "            cfg,\n",
    "            dtrain,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dval, 'validation')],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        # 6) now re‐tune the exact #trees on YOUR root_score\n",
    "        best_iter      = bst.best_iteration\n",
    "        best_local_sc  = -1\n",
    "        best_local_it  = best_iter\n",
    "\n",
    "        for it in (best_iter-20, best_iter, best_iter+20):\n",
    "            it = int(np.clip(it, 1, best_iter))\n",
    "            p_it = bst.predict(dval, iteration_range=(0, it))\n",
    "            sc_it = root_score(val.sentence.values, y_val, p_it)\n",
    "            if sc_it > best_local_sc:\n",
    "                best_local_sc, best_local_it = sc_it, it\n",
    "\n",
    "        # 7) if this combo is the best so far, keep it\n",
    "        if best_local_sc > best_sc:\n",
    "            best_sc    = best_local_sc\n",
    "            best_cfg   = dict(cfg, ntree_limit=best_local_it)\n",
    "            best_bst   = bst\n",
    "\n",
    "    print(f\"{lang:12s} → val-root-acc={best_sc:.3f}  \"\n",
    "          f\"best_round={best_cfg['ntree_limit']}  cfg={best_cfg}\")\n",
    "\n",
    "    # store scaler, final booster and tuned tree‐count\n",
    "    models[lang] = (scaler, best_bst, best_cfg['ntree_limit'])\n",
    "\n",
    "print(f\"\\nTuning completed in {timedelta(seconds=time()-t0)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c7f15f-8ab9-41b0-a28c-afccac375361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data…\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data…\")\n",
    "test_feats = pd.read_csv(TEST_FEATS_PATH)\n",
    "raw_test   = pd.read_csv(TEST_META_PATH)\n",
    "raw_test['edgelist'] = raw_test['edgelist'].apply(ast.literal_eval)\n",
    "\n",
    "test_df = test_feats.merge(\n",
    "    raw_test[['id','language','sentence']],\n",
    "    on=['id','language','sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf6f7ae-e8ac-487d-a106-f6297a8088c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set…\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting on test set…\")\n",
    "results = []\n",
    "for tid, grp in test_df.groupby('id', sort=False):\n",
    "    # ← unpack scaler, model and tuned tree-count\n",
    "    scaler, bst, ntree_limit = models[grp.language.iloc[0]]\n",
    "\n",
    "    # feature matrix for this sentence\n",
    "    Xs = scaler.transform(grp[FEATURES].values)\n",
    "    dm = xgb.DMatrix(Xs)\n",
    "\n",
    "    # ← use dm and per-language ntree_limit\n",
    "    probs = bst.predict(dm, iteration_range=(0, ntree_limit))\n",
    "\n",
    "    pick = int(grp.vertex.values[probs.argmax()])\n",
    "    results.append({'id': tid, 'root_pred': pick})\n",
    "\n",
    "submission = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee65f384-d3dd-496b-8df5-d621740dff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Test accuracy: 51.544% (5358/10395)\n",
      "\n",
      "Some mis‐predictions:\n",
      "   id  root_pred  root\n",
      "0   1         38     4\n",
      "2   3         15     5\n",
      "3   4         14    15\n",
      "4   5          3     9\n",
      "5   6          3    17\n"
     ]
    }
   ],
   "source": [
    "truth = pd.read_csv('../../data/labeled_test.csv')\n",
    "cmp   = submission.merge(truth, on='id')\n",
    "cmp['correct'] = cmp['root_pred'] == cmp['root']\n",
    "acc = cmp['correct'].mean()\n",
    "\n",
    "print(f\"XGB Test accuracy: {acc:.3%} ({cmp['correct'].sum()}/{len(cmp)})\\n\")\n",
    "print(\"Some mis‐predictions:\")\n",
    "print(cmp.loc[~cmp['correct'], ['id','root_pred','root']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697ba353-1443-465d-896a-d1d3f2ea0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../../data/submission_XGB_advanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6084255-c640-4031-a09f-d8dbd9801359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML-project(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
