{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c786a11c-d85b-4b59-8444-ce19308d1d2b",
   "metadata": {},
   "source": [
    "# XGBoost Modeling Pipeline (main non-linear model)\n",
    "\n",
    "This is our main non-linear model, where we build and tune per-language XGBoost classifiers to predict the root node. The main tricks/adjustments that we used over the \"vanilla\" XGBoost workflow are:\n",
    "- Custom evaluation metric (root_score) selecting exactly one root per sentence.\n",
    "- Sentence-wise grouping during train/validation splits to avoid data leakage.\n",
    "- Class‐imbalance handling via scale_pos_weight.\n",
    "- Regularization (L1/L2) and parameter grid search.\n",
    "- GPU acceleration (cuda) with early stopping to speed up the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a624ef1-ee6a-4ec8-a7ed-296b49cd228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, ast\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.model_selection  import GroupShuffleSplit\n",
    "from itertools                import product\n",
    "from tqdm                     import tqdm\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e29677",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_FEATS_PATH   = '../data/normalized_expanded_train.csv'\n",
    "TRAIN_META_PATH    = '../data/train.csv'\n",
    "TEST_FEATS_PATH    = '../data/normalized_expanded_test.csv'\n",
    "TEST_META_PATH     = '../data/test.csv'\n",
    "LABELED_TEST_PATH  = '../data/labeled_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f645ce5-8641-4e60-9958-08b0e1cf35da",
   "metadata": {},
   "source": [
    "We use the centrality scores and sentence length as features. We are aware that normalization is not a necessary step for XBG, but since our preprocessing already handled it, it remained in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d36e76-483e-4e7b-8cfb-81cd05fe609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'n','degree','closeness','harmonic','betweeness','load','pagerank',\n",
    "    'eigenvector','katz','information','current_flow_betweeness',\n",
    "    'percolation','second_order','laplacian'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34560c7-0e71-4bc8-ad95-fd69016d01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "  'max_depth':        [4,6,8],\n",
    "  'eta':               [0.01,0.05,0.1],\n",
    "  'subsample':        [0.7,1.0],\n",
    "  'colsample_bytree': [0.7,1.0],\n",
    "  'gamma':            [0,1],\n",
    "  # new ones:\n",
    "  'min_child_weight': [1,5,10],\n",
    "  'reg_alpha':        [0,0.01,0.1],\n",
    "  'reg_lambda':       [1,10,100],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6732bd4-4a74-4b56-bf88-ab40cbbc5c57",
   "metadata": {},
   "source": [
    "We use a custom scoring function, a sentence-level score that picks the node with maximum predicted probability per sentence:\n",
    "\n",
    "$$\n",
    "\\mathrm{root\\_score}\n",
    "\\;=\\;\n",
    "\\frac{1}{|S|}\\,\n",
    "\\sum_{s \\in S}\n",
    "\\mathbf{1}\\!\\bigl(\\arg\\max_{v \\in s}\\,\\hat p_v \\;=\\;\\mathrm{true\\_root}(s)\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93c55eb-4245-409e-ab89-f259ff3389a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom root‐accuracy scoring (1 root per sentence)\n",
    "def root_score(sent_ids, y_true, probs):\n",
    "    dfp = pd.DataFrame({'sent': sent_ids, 'y': y_true, 'p': probs})\n",
    "    picks = dfp.loc[dfp.groupby('sent')['p'].idxmax()]\n",
    "    return (picks.y == 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "791b5109-89df-44c7-8fdf-1badd4096e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data…\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data…\")\n",
    "exp  = pd.read_csv(TRAIN_FEATS_PATH)\n",
    "meta = pd.read_csv(TRAIN_META_PATH)\n",
    "meta['edgelist'] = meta['edgelist'].apply(ast.literal_eval)\n",
    "df   = exp.merge(\n",
    "    meta[['language','sentence','edgelist','root']],\n",
    "    on=['language','sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3956b1-1e29-4b4b-ac27-869522942726",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "We iterate over each language, performing:\n",
    "1. 80/20 GroupShuffleSplit by sentence\n",
    "2. DMatrix creation\n",
    "3. $$\n",
    "\\text{scale\\_pos\\_weight}\n",
    "\\;=\\;\n",
    "\\frac{\\#\\text{negatives}}{\\#\\text{positives}}\n",
    "$$\n",
    "4. Grid search over all hyperparams, training with early stopping on validation error\n",
    "5. Re-tune the number of trees based on our root_score over three candidate iterations:\n",
    "    - best_iteration ±20\n",
    "6. Store the best model, scaler, and tuned ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6174aae8-30a8-4893-b12f-472c98999146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning per language XGB on GPU with early stopping\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▌                                                                                                                | 1/21 [12:19<4:06:37, 739.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic       -> val-root-acc=0.570  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.4775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████████▏                                                                                                          | 2/21 [30:14<4:56:33, 936.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese      -> val-root-acc=0.340  best_round=6  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0.1, 'lambda': 1, 'scale_pos_weight': 17.5475, 'seed': 42, 'verbosity': 0, 'ntree_limit': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████████████▊                                                                                                     | 3/21 [47:00<4:50:35, 968.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech        -> val-root-acc=0.610  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.0875, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████████████                                                                                              | 4/21 [1:01:27<4:22:59, 928.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English      -> val-root-acc=0.680  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.715, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████▌                                                                                        | 5/21 [1:12:31<3:42:09, 833.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finnish      -> val-root-acc=0.570  best_round=7  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 12.5775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████████████████▏                                                                                  | 6/21 [1:27:46<3:35:13, 860.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French       -> val-root-acc=0.480  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 21.4075, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████████████████▋                                                                             | 7/21 [1:44:24<3:31:19, 905.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galician     -> val-root-acc=0.550  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.0975, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████████████████████▏                                                                       | 8/21 [1:57:32<3:08:09, 868.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German       -> val-root-acc=0.650  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 17.695, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████████████████████████▋                                                                  | 9/21 [2:13:58<3:01:01, 905.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hindi        -> val-root-acc=0.320  best_round=17  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.6575, 'seed': 42, 'verbosity': 0, 'ntree_limit': 17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████████████████████▊                                                            | 10/21 [2:27:51<2:41:52, 882.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Icelandic    -> val-root-acc=0.540  best_round=0  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.73, 'seed': 42, 'verbosity': 0, 'ntree_limit': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████████████████████████████████████████████▏                                                      | 11/21 [2:44:39<2:33:29, 920.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indonesian   -> val-root-acc=0.560  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 1, 'scale_pos_weight': 16.1, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████████████████████████▋                                                 | 12/21 [3:04:07<2:29:26, 996.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italian      -> val-root-acc=0.550  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.595, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████████████████████████████████████████████████▌                                           | 13/21 [3:27:27<2:29:08, 1118.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese     -> val-root-acc=0.150  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 1, 'scale_pos_weight': 24.7675, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████████████████████████████████████████████████████                                      | 14/21 [3:45:01<2:08:13, 1099.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korean       -> val-root-acc=0.370  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.1, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 14.02, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████████████▏                                | 15/21 [3:55:29<1:35:41, 956.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish       -> val-root-acc=0.650  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 14.8325, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████████████████████████████████████████████████████████████▌                           | 16/21 [4:11:22<1:19:38, 955.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portuguese   -> val-root-acc=0.510  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 19.825, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████                      | 17/21 [4:25:42<1:01:48, 927.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian      -> val-root-acc=0.670  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 15.4125, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                | 18/21 [4:41:10<46:21, 927.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish      -> val-root-acc=0.500  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 4, 'eta': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 20.0925, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 19/21 [4:55:56<30:29, 914.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swedish      -> val-root-acc=0.650  best_round=8  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 6, 'eta': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 10, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 16.1525, 'seed': 42, 'verbosity': 0, 'ntree_limit': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 20/21 [5:14:16<16:10, 970.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thai         -> val-root-acc=0.620  best_round=1  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 6, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 0.7, 'gamma': 0, 'min_child_weight': 5, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 21.0775, 'seed': 42, 'verbosity': 0, 'ntree_limit': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [5:25:07<00:00, 928.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turkish      -> val-root-acc=0.480  best_round=22  cfg={'objective': 'binary:logistic', 'eval_metric': 'error', 'tree_method': 'hist', 'device': 'cuda', 'max_depth': 8, 'eta': 0.01, 'subsample': 1.0, 'colsample_bytree': 1.0, 'gamma': 0, 'min_child_weight': 1, 'alpha': 0, 'lambda': 100, 'scale_pos_weight': 13.8225, 'seed': 42, 'verbosity': 0, 'ntree_limit': 22}\n",
      "\n",
      "Tuning completed in 5:25:07.645642\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "t0 = time()\n",
    "print(\"Tuning per language XGB on GPU with early stopping\\n\")\n",
    "\n",
    "for lang in tqdm(sorted(df.language.unique())):\n",
    "    sub = df[df.language == lang].reset_index(drop=True)\n",
    "\n",
    "    # 80/20 sentence-wise split (to avoid leakage)\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    tr_idx, val_idx = next(gss.split(sub, sub.root, groups=sub.sentence))\n",
    "    train, val = sub.iloc[tr_idx], sub.iloc[val_idx]\n",
    "\n",
    "    # raw feature matrices\n",
    "    X_tr  = train[FEATURES].values\n",
    "    y_tr  = (train.root == train.vertex).astype(int)\n",
    "    X_val = val[FEATURES].values\n",
    "    y_val = (val.root   == val.vertex ).astype(int)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_tr,  label=y_tr)\n",
    "    dval   = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # class-imbalance weight\n",
    "    pos = y_tr.sum();  neg = len(y_tr) - pos\n",
    "    spw = (neg/pos) if pos > 0 else 1.0\n",
    "\n",
    "    best_sc, best_cfg, best_bst = -1, None, None\n",
    "\n",
    "    # grid search\n",
    "    for md, eta, subs, colsm, gm, mcw, alpha, lmbda in product(\n",
    "        param_grid['max_depth'],\n",
    "        param_grid['eta'],\n",
    "        param_grid['subsample'],\n",
    "        param_grid['colsample_bytree'],\n",
    "        param_grid['gamma'],\n",
    "        param_grid['min_child_weight'],\n",
    "        param_grid['reg_alpha'],\n",
    "        param_grid['reg_lambda'],\n",
    "    ):\n",
    "        cfg = {\n",
    "            'objective':        'binary:logistic',\n",
    "            'eval_metric':      'error',\n",
    "            'tree_method':      'hist',\n",
    "            'device':           'cuda',\n",
    "            'max_depth':        md,\n",
    "            'eta':              eta,\n",
    "            'subsample':        subs,\n",
    "            'colsample_bytree': colsm,\n",
    "            'gamma':            gm,\n",
    "            'min_child_weight': mcw,\n",
    "            'alpha':            alpha,\n",
    "            'lambda':           lmbda,\n",
    "            'scale_pos_weight': spw,\n",
    "            'seed':             42,\n",
    "            'verbosity':        0,\n",
    "        }\n",
    "\n",
    "        bst = xgb.train(\n",
    "            cfg, dtrain,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dval, 'validation')],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "\n",
    "        best_iter     = bst.best_iteration\n",
    "        best_local_sc = -1\n",
    "        best_local_it = best_iter\n",
    "\n",
    "        for it in (best_iter-20, best_iter, best_iter+20):\n",
    "            it = int(np.clip(it, 1, best_iter))\n",
    "            p  = bst.predict(dval, iteration_range=(0, it))\n",
    "            sc = root_score(val.sentence.values, y_val, p)\n",
    "            if sc > best_local_sc:\n",
    "                best_local_sc, best_local_it = sc, it\n",
    "\n",
    "        if best_local_sc > best_sc:\n",
    "            best_sc  = best_local_sc\n",
    "            best_cfg = dict(cfg, ntree_limit=best_local_it)\n",
    "            best_bst = bst\n",
    "\n",
    "    print(f\"{lang:12s} -> val-root-acc={best_sc:.3f}  \"\n",
    "          f\"best_round={best_cfg['ntree_limit']}  cfg={best_cfg}\")\n",
    "\n",
    "    # store only the booster and tuned tree-count\n",
    "    models[lang] = (best_bst, best_cfg['ntree_limit'])\n",
    "\n",
    "print(f\"\\nTuning completed in {timedelta(seconds=time()-t0)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c7f15f-8ab9-41b0-a28c-afccac375361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data…\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data…\")\n",
    "test_feats = pd.read_csv(TEST_FEATS_PATH)\n",
    "raw_test   = pd.read_csv(TEST_META_PATH)\n",
    "raw_test['edgelist'] = raw_test['edgelist'].apply(ast.literal_eval)\n",
    "\n",
    "test_df = test_feats.merge(\n",
    "    raw_test[['id','language','sentence']],\n",
    "    on=['id','language','sentence']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a814f-17ea-4ebf-ad4f-646220e9a42f",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Here, we pick the vertex with highest predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf6f7ae-e8ac-487d-a106-f6297a8088c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set…\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting on test set…\")\n",
    "results = []\n",
    "\n",
    "for tid, grp in test_df.groupby('id', sort=False):\n",
    "    # unpack booster and ntree_limit\n",
    "    bst, ntree_limit = models[grp.language.iloc[0]]\n",
    "\n",
    "    Xs = grp[FEATURES].values          # raw features\n",
    "    dm = xgb.DMatrix(Xs)\n",
    "    probs = bst.predict(dm, iteration_range=(0, ntree_limit))\n",
    "\n",
    "    pick = int(grp.vertex.values[probs.argmax()])\n",
    "    results.append({'id': tid, 'root_pred': pick})\n",
    "\n",
    "submission = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "697ba353-1443-465d-896a-d1d3f2ea0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission_XGB_advanced_new.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML-project(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
