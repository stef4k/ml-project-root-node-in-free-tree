{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55429ae",
   "metadata": {},
   "source": [
    "# Linear Approach\n",
    "Starting by importing the right libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c508369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV, StratifiedGroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82005bf0",
   "metadata": {},
   "source": [
    "Next we read the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f0da078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>vertex</th>\n",
       "      <th>n</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>harmonic</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>load</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>information</th>\n",
       "      <th>current_flow_betweeness</th>\n",
       "      <th>percolation</th>\n",
       "      <th>second_order</th>\n",
       "      <th>laplacian</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.133038</td>\n",
       "      <td>-0.558160</td>\n",
       "      <td>-0.308023</td>\n",
       "      <td>-0.676962</td>\n",
       "      <td>-0.676962</td>\n",
       "      <td>0.409538</td>\n",
       "      <td>-0.327923</td>\n",
       "      <td>0.074694</td>\n",
       "      <td>-0.558160</td>\n",
       "      <td>-0.676962</td>\n",
       "      <td>-0.676962</td>\n",
       "      <td>0.489782</td>\n",
       "      <td>-0.031273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>-1.396899</td>\n",
       "      <td>-1.111953</td>\n",
       "      <td>-1.442852</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.313638</td>\n",
       "      <td>-1.131636</td>\n",
       "      <td>-1.460142</td>\n",
       "      <td>-1.111953</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>1.149235</td>\n",
       "      <td>-1.469827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.662975</td>\n",
       "      <td>0.111311</td>\n",
       "      <td>0.741550</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>1.885752</td>\n",
       "      <td>0.745846</td>\n",
       "      <td>1.519954</td>\n",
       "      <td>0.111311</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>-0.198147</td>\n",
       "      <td>1.407281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>-1.396899</td>\n",
       "      <td>-0.618060</td>\n",
       "      <td>-0.907167</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.449223</td>\n",
       "      <td>-0.639537</td>\n",
       "      <td>-1.315616</td>\n",
       "      <td>-0.618060</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>-1.126101</td>\n",
       "      <td>0.556481</td>\n",
       "      <td>-1.110188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>0.133038</td>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.880961</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>-0.074579</td>\n",
       "      <td>1.113070</td>\n",
       "      <td>0.390094</td>\n",
       "      <td>0.812630</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>0.413803</td>\n",
       "      <td>-0.837635</td>\n",
       "      <td>0.688004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  sentence  vertex   n    degree  closeness  harmonic  betweeness  \\\n",
       "0  Japanese         2       6  23  0.133038  -0.558160 -0.308023   -0.676962   \n",
       "1  Japanese         2       4  23 -1.396899  -1.111953 -1.442852   -1.126101   \n",
       "2  Japanese         2       2  23  1.662975   0.111311  0.741550    0.135764   \n",
       "3  Japanese         2      23  23 -1.396899  -0.618060 -0.907167   -1.126101   \n",
       "4  Japanese         2      20  23  0.133038   0.812630  0.880961    0.413803   \n",
       "\n",
       "       load  pagerank  eigenvector      katz  information  \\\n",
       "0 -0.676962  0.409538    -0.327923  0.074694    -0.558160   \n",
       "1 -1.126101 -1.313638    -1.131636 -1.460142    -1.111953   \n",
       "2  0.135764  1.885752     0.745846  1.519954     0.111311   \n",
       "3 -1.126101 -1.449223    -0.639537 -1.315616    -0.618060   \n",
       "4  0.413803 -0.074579     1.113070  0.390094     0.812630   \n",
       "\n",
       "   current_flow_betweeness  percolation  second_order  laplacian  is_root  \n",
       "0                -0.676962    -0.676962      0.489782  -0.031273        0  \n",
       "1                -1.126101    -1.126101      1.149235  -1.469827        0  \n",
       "2                 0.135764     0.135764     -0.198147   1.407281        0  \n",
       "3                -1.126101    -1.126101      0.556481  -1.110188        0  \n",
       "4                 0.413803     0.413803     -0.837635   0.688004        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/normalized_expanded_train.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e921a9ca",
   "metadata": {},
   "source": [
    "Now we will focus only in one language, opting to go for `Polish`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83483938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>vertex</th>\n",
       "      <th>n</th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>harmonic</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>load</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>katz</th>\n",
       "      <th>information</th>\n",
       "      <th>current_flow_betweeness</th>\n",
       "      <th>percolation</th>\n",
       "      <th>second_order</th>\n",
       "      <th>laplacian</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130343</th>\n",
       "      <td>Polish</td>\n",
       "      <td>571</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.021055</td>\n",
       "      <td>-1.296689</td>\n",
       "      <td>-1.416117</td>\n",
       "      <td>-0.953935</td>\n",
       "      <td>-0.953935</td>\n",
       "      <td>-0.957508</td>\n",
       "      <td>-1.299322</td>\n",
       "      <td>-1.126988</td>\n",
       "      <td>-1.296689</td>\n",
       "      <td>-0.953935</td>\n",
       "      <td>-0.953935</td>\n",
       "      <td>1.397441</td>\n",
       "      <td>-1.154014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130950</th>\n",
       "      <td>Polish</td>\n",
       "      <td>663</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1.262672</td>\n",
       "      <td>0.593176</td>\n",
       "      <td>0.936140</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>1.342575</td>\n",
       "      <td>0.789891</td>\n",
       "      <td>1.143079</td>\n",
       "      <td>0.593176</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>-0.647289</td>\n",
       "      <td>0.950139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132643</th>\n",
       "      <td>Polish</td>\n",
       "      <td>871</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>-1.135860</td>\n",
       "      <td>0.470146</td>\n",
       "      <td>0.021320</td>\n",
       "      <td>-0.970478</td>\n",
       "      <td>-0.970478</td>\n",
       "      <td>-1.364014</td>\n",
       "      <td>0.360487</td>\n",
       "      <td>-0.881947</td>\n",
       "      <td>0.470146</td>\n",
       "      <td>-0.970478</td>\n",
       "      <td>-0.970478</td>\n",
       "      <td>-0.533836</td>\n",
       "      <td>-0.556987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133482</th>\n",
       "      <td>Polish</td>\n",
       "      <td>977</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2.110579</td>\n",
       "      <td>2.278207</td>\n",
       "      <td>2.167471</td>\n",
       "      <td>2.558252</td>\n",
       "      <td>2.558252</td>\n",
       "      <td>1.952752</td>\n",
       "      <td>2.542000</td>\n",
       "      <td>2.238517</td>\n",
       "      <td>2.278207</td>\n",
       "      <td>2.558252</td>\n",
       "      <td>2.558252</td>\n",
       "      <td>-2.121269</td>\n",
       "      <td>2.483897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132470</th>\n",
       "      <td>Polish</td>\n",
       "      <td>843</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.957826</td>\n",
       "      <td>-0.115115</td>\n",
       "      <td>-0.245679</td>\n",
       "      <td>-0.872960</td>\n",
       "      <td>-0.872960</td>\n",
       "      <td>-1.028892</td>\n",
       "      <td>0.145024</td>\n",
       "      <td>-0.796896</td>\n",
       "      <td>-0.115115</td>\n",
       "      <td>-0.872960</td>\n",
       "      <td>-0.872960</td>\n",
       "      <td>0.014297</td>\n",
       "      <td>-0.577092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       language  sentence  vertex   n    degree  closeness  harmonic  \\\n",
       "130343   Polish       571       5  16 -1.021055  -1.296689 -1.416117   \n",
       "130950   Polish       663       9  11  1.262672   0.593176  0.936140   \n",
       "132643   Polish       871       4  19 -1.135860   0.470146  0.021320   \n",
       "133482   Polish       977       2  20  2.110579   2.278207  2.167471   \n",
       "132470   Polish       843      12  22 -0.957826  -0.115115 -0.245679   \n",
       "\n",
       "        betweeness      load  pagerank  eigenvector      katz  information  \\\n",
       "130343   -0.953935 -0.953935 -0.957508    -1.299322 -1.126988    -1.296689   \n",
       "130950    0.687714  0.687714  1.342575     0.789891  1.143079     0.593176   \n",
       "132643   -0.970478 -0.970478 -1.364014     0.360487 -0.881947     0.470146   \n",
       "133482    2.558252  2.558252  1.952752     2.542000  2.238517     2.278207   \n",
       "132470   -0.872960 -0.872960 -1.028892     0.145024 -0.796896    -0.115115   \n",
       "\n",
       "        current_flow_betweeness  percolation  second_order  laplacian  is_root  \n",
       "130343                -0.953935    -0.953935      1.397441  -1.154014        0  \n",
       "130950                 0.687714     0.687714     -0.647289   0.950139        0  \n",
       "132643                -0.970478    -0.970478     -0.533836  -0.556987        0  \n",
       "133482                 2.558252     2.558252     -2.121269   2.483897        0  \n",
       "132470                -0.872960    -0.872960      0.014297  -0.577092        0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polish_data = data[data.language == 'Polish'].sample(frac=1).copy()\n",
    "polish_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4a227",
   "metadata": {},
   "source": [
    "Now we can split the data in train and test in a way to keep the same sentences (sentence level and node level of sentence) in the same group. Each sentence and its nodes will only be found in train or validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7693d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = polish_data.copy()#.drop(['is_root','language','n'], axis=1).copy()\n",
    "y = polish_data['is_root'].copy()\n",
    "\n",
    "groups = polish_data['sentence']\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_val= X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c84185",
   "metadata": {},
   "source": [
    "Now we also define the cross validation strategy. We also split the training data in 5 different folds ensuring that data of of the same sentence can not be found in different folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c45bd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedGroupKFold(n_splits=5)\n",
    "groups = X_train['sentence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaec98e",
   "metadata": {},
   "source": [
    "Next we can define the logistic regression model parameters that we want to try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af856faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=2)\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0, 0.5, 1],\n",
    "    'max_iter': [1000, 2500, 5000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc584422",
   "metadata": {},
   "source": [
    "We use a custom scoring method that picks one root per sentence. For each sentence, it chooses the node with the highest chance of being the root (class 1). The final score is just the percentage of sentences where we picked the correct root.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3bbde6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_prediction_score(estimator, X, y_true):\n",
    "    \"\"\"\n",
    "    Scoring function that extracts sentence IDs from X and computes\n",
    "    root prediction accuracy per sentence.\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_ids = X['sentence'].values\n",
    "    X_features = X.copy()\n",
    "    # Predict probabilities\n",
    "    probs = estimator.predict_proba(X_features)[:, 1]\n",
    "    # Build DataFrame for groupby\n",
    "    df_pred = pd.DataFrame({\n",
    "        'sentence': sentence_ids,\n",
    "        'is_root': y_true,\n",
    "        'root_prob': probs\n",
    "    })\n",
    "\n",
    "    predicted_roots = df_pred.loc[df_pred.groupby('sentence')['root_prob'].idxmax()]\n",
    "    accuracy = float((predicted_roots['is_root'] == 1).mean())\n",
    "    return accuracy\n",
    "\n",
    "root_scorer = make_scorer(root_prediction_score, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b790f57",
   "metadata": {},
   "source": [
    "Now we can do the gridsearch, combining defined parameters, the custom scoring function, the cross validation strategy (that ensures no data leakage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aae5bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "225 fits failed out of a total of 900.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "147 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.265  0.2625 0.2625    nan 0.2575 0.265  0.265     nan 0.2625 0.265\n",
      " 0.265     nan 0.265  0.2625 0.265     nan 0.2575 0.265  0.2625    nan\n",
      " 0.2625 0.265  0.2625    nan 0.265  0.2625 0.265     nan 0.2575 0.265\n",
      " 0.2575    nan 0.2625 0.265  0.2625    nan 0.2675 0.265  0.265     nan\n",
      " 0.2675 0.2675 0.2675    nan 0.2675 0.2675 0.2675    nan 0.2675 0.265\n",
      " 0.265     nan 0.2675 0.2675 0.265     nan 0.2675 0.2675 0.265     nan\n",
      " 0.2675 0.265  0.2675    nan 0.2675 0.2675 0.2675    nan 0.2675 0.2675\n",
      " 0.2675    nan 0.265  0.2675 0.2675    nan 0.2625 0.2675 0.2675    nan\n",
      " 0.2625 0.2675 0.2675    nan 0.265  0.2675 0.2675    nan 0.2625 0.2675\n",
      " 0.2675    nan 0.2625 0.2675 0.2675    nan 0.265  0.2675 0.265     nan\n",
      " 0.2625 0.2675 0.2625    nan 0.2625 0.2675 0.2625    nan 0.2675 0.265\n",
      " 0.265     nan 0.2675 0.265  0.265     nan 0.2675 0.265  0.265     nan\n",
      " 0.2675 0.265  0.265     nan 0.2675 0.265  0.2675    nan 0.2675 0.265\n",
      " 0.2675    nan 0.2675 0.265  0.2675    nan 0.2675 0.265  0.2675    nan\n",
      " 0.2675 0.265  0.2675    nan 0.265  0.2675 0.2675    nan 0.2675 0.265\n",
      " 0.265     nan 0.2675 0.265  0.265     nan 0.265  0.2675 0.265     nan\n",
      " 0.2675 0.265  0.2675    nan 0.2675 0.265  0.2675    nan 0.265  0.2675\n",
      " 0.265     nan 0.2675 0.265  0.2675    nan 0.2675 0.265  0.2675    nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.1, 'l1_ratio': 0, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.26749999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stef4\\Documents\\ml-project-root-node-in-free-tree\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_cols = [\n",
    "    'sentence', 'degree', 'closeness', 'harmonic', 'betweeness', 'load', 'pagerank',\n",
    "    'eigenvector', 'katz', 'information', 'current_flow_betweeness',\n",
    "    'percolation', 'second_order', 'laplacian'\n",
    "]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=root_prediction_score,\n",
    "    n_jobs=7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train[feature_cols], y_train, groups=groups)\n",
    "\n",
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a3cd3",
   "metadata": {},
   "source": [
    "We will use the best estimator found to see the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df451647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "root_prediction_score(best_estimator, X_val[feature_cols], y_val)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML-project(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
