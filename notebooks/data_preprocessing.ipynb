{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f450335",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook describes the preprocessing steps and an exploratory analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68304a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054a29b",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3682e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>edgelist</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>[(6, 4), (2, 6), (2, 23), (20, 2), (15, 20), (...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>[(8, 9), (14, 8), (4, 14), (5, 4), (1, 2), (6,...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>[(2, 10), (2, 14), (4, 2), (16, 4), (6, 16), (...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>[(30, 1), (14, 24), (21, 14), (3, 21), (7, 3),...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>[(19, 13), (16, 19), (2, 16), (4, 10), (4, 15)...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  sentence   n                                           edgelist  \\\n",
       "0  Japanese         2  23  [(6, 4), (2, 6), (2, 23), (20, 2), (15, 20), (...   \n",
       "1  Japanese         5  18  [(8, 9), (14, 8), (4, 14), (5, 4), (1, 2), (6,...   \n",
       "2  Japanese         8  33  [(2, 10), (2, 14), (4, 2), (16, 4), (6, 16), (...   \n",
       "3  Japanese        11  30  [(30, 1), (14, 24), (21, 14), (3, 21), (7, 3),...   \n",
       "4  Japanese        12  19  [(19, 13), (16, 19), (2, 16), (4, 10), (4, 15)...   \n",
       "\n",
       "   root  \n",
       "0    10  \n",
       "1    10  \n",
       "2     3  \n",
       "3    30  \n",
       "4    11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ee7e8",
   "metadata": {},
   "source": [
    "Next we check the types and nulls values per column of the training data. No null values are found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0559da58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10500 entries, 0 to 10499\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   language  10500 non-null  object\n",
      " 1   sentence  10500 non-null  int64 \n",
      " 2   n         10500 non-null  int64 \n",
      " 3   edgelist  10500 non-null  object\n",
      " 4   root      10500 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 410.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0024cf",
   "metadata": {},
   "source": [
    "Now we can check some basic statistics of the numeric columns.\n",
    "- On average each sentence has $18.8$ words\n",
    "- The root predicted node can be from the 1st till the 68th node (depending the size of the sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf4a3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>n</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>494.778000</td>\n",
       "      <td>18.807524</td>\n",
       "      <td>9.844476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>290.256632</td>\n",
       "      <td>8.190593</td>\n",
       "      <td>7.207740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>233.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>483.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>742.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>995.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence             n          root\n",
       "count  10500.000000  10500.000000  10500.000000\n",
       "mean     494.778000     18.807524      9.844476\n",
       "std      290.256632      8.190593      7.207740\n",
       "min        2.000000      3.000000      1.000000\n",
       "25%      233.500000     13.000000      4.000000\n",
       "50%      483.000000     18.000000      8.000000\n",
       "75%      742.250000     23.000000     14.000000\n",
       "max      995.000000     70.000000     68.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ba3b8",
   "metadata": {},
   "source": [
    "In the training data we can find 21 languages with 500 sentences for each language, producing $10,500$ total rows of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990245d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total languages: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "language  \n",
       "Arabic        500\n",
       "Chinese       500\n",
       "Czech         500\n",
       "English       500\n",
       "Finnish       500\n",
       "French        500\n",
       "Galician      500\n",
       "German        500\n",
       "Hindi         500\n",
       "Icelandic     500\n",
       "Indonesian    500\n",
       "Italian       500\n",
       "Japanese      500\n",
       "Korean        500\n",
       "Polish        500\n",
       "Portuguese    500\n",
       "Russian       500\n",
       "Spanish       500\n",
       "Swedish       500\n",
       "Thai          500\n",
       "Turkish       500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total languages: ' + str(data[['language']].value_counts().shape[0]))\n",
    "data[['language']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff0f76",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "Now the dataset will be transformed into a training set suitable for binary classification models using centralities as\n",
    "vertex features\n",
    "\n",
    "A function is created that transform an edge list into a networkx graph calculating the centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a771247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centralities(edgelist):\n",
    "    T = nx.from_edgelist(edgelist)\n",
    "    dc = nx.degree_centrality(T)\n",
    "    cc = nx.harmonic_centrality(T)\n",
    "    bc = nx.betweenness_centrality(T)\n",
    "    pc = nx.pagerank(T)\n",
    "    return {v: (dc[v], cc[v], bc[v], pc[v]) for v in T}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f46aaf",
   "metadata": {},
   "source": [
    "Now we iterate over each row of the training data, transforming it into a graph and calculating the centralities for every node. The new binary dataset contains the features of `language`, `sentence`,`n`, `vertex`, centrality scores and `is_root` (which takes values of 0 or 1 if the particular node is a root node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f1f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "      <th>vertex</th>\n",
       "      <th>n</th>\n",
       "      <th>degree</th>\n",
       "      <th>harmonic</th>\n",
       "      <th>betweeness</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>is_root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>5.823846</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.048565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>4.561122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>6.991703</td>\n",
       "      <td>0.255411</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>5.157179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>7.146825</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.042552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  sentence  vertex   n    degree  harmonic  betweeness  pagerank  \\\n",
       "0  Japanese         2       6  23  0.090909  5.823846    0.090909  0.048565   \n",
       "1  Japanese         2       4  23  0.045455  4.561122    0.000000  0.027162   \n",
       "2  Japanese         2       2  23  0.136364  6.991703    0.255411  0.066901   \n",
       "3  Japanese         2      23  23  0.045455  5.157179    0.000000  0.025477   \n",
       "4  Japanese         2      20  23  0.090909  7.146825    0.311688  0.042552   \n",
       "\n",
       "   is_root  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['language', 'sentence', 'vertex', 'n',\n",
    "           'degree', 'harmonic',\n",
    "           'betweeness', 'pagerank',\n",
    "           'is_root']\n",
    "\n",
    "binary_data_list = []\n",
    "\n",
    "# Saving column of edges as a list instead of a string\n",
    "data['edgelist'] = data['edgelist'].apply(ast.literal_eval)\n",
    "\n",
    "for row in data.itertuples(index=False):\n",
    "    target = row.root\n",
    "    \n",
    "    for node, (degree, harmonic, betweeness,\n",
    "              pagerank) in centralities(row.edgelist).items():\n",
    "        new_row = {'language': row.language,\n",
    "                   'sentence': row.sentence,\n",
    "                   'vertex': node,\n",
    "                   'n': row.n,\n",
    "                   'degree': degree,\n",
    "                   'harmonic': harmonic,\n",
    "                   'betweeness': betweeness,\n",
    "                   'pagerank': pagerank,\n",
    "                   'is_root': 1 if node == target else 0}\n",
    "\n",
    "        binary_data_list.append(new_row)\n",
    "\n",
    "expanded_data = pd.DataFrame(binary_data_list, columns=columns)\n",
    "expanded_data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618a64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML-project(myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
